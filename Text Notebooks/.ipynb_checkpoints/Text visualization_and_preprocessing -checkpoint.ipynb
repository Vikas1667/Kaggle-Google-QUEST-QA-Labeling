{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### numerical processing\n",
    "import numpy as np\n",
    "###text preprocessing\n",
    "import pandas as pd\n",
    "from collections import  Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from string import punctuation\n",
    "import networkx\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "# nltk.download('wordnet')\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "###text visualization\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-8824b11be10a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequence\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dash\n",
    "import dash_core_components\n",
    "import dash_html_components\n",
    "import dash.dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending an \"affidavit\" it is a dispute between Rashi and Rabbeinu Tam.\r\n",
      "\r\n",
      "Devarim 19:15:\r\n",
      "\r\n",
      "\r\n",
      "  לא יקום עד אחד באיש לכל עון ולכל חטאת בכל חטא אשר יחטא על פי שני עדים או על פי שלשה עדים יקום דבר\r\n",
      "\r\n",
      "\r\n",
      "Rashi:\r\n",
      "\r\n",
      "\r\n",
      "  ולא שיכתבו עדותם באגרת וישלחו לבית דין\r\n",
      "  \r\n",
      "  And not that they write their testimony in a letter and send it to Beis Din\r\n",
      "\r\n",
      "\r\n",
      "Tosefos Bava Basra 40a (continued from 39b):\r\n",
      "\r\n",
      "\r\n",
      "  ועוד אומר ר\"י ששמע מן ר\"ת שנוהגים לשלח העדים עדותם באיגרת לב\"ד וחשיב עדות והא דדרשינן בספרי. מפיהם ולא מפי כתבם לא אתא אלא למעוטי דוקא אלם שאינו בר הגדה אבל ראוי להגדה אין הגדה מעכבת בו \r\n",
      "  \r\n",
      "  R\"i said that he heard from Rabbeinu Tam that the custom is to send testimony by a letter and it is considered [valid] testimony.  And that which it expounds in the Sifre \"From their mouths and not from their writing\" is only coming to exclude a mute who is not able to speak, but someone who is able to speak does not need to speak.\r\n",
      "\r\n",
      "\r\n",
      "Rambam concludes it is not allowed, but in monetary law the Chachomim enacted that it would be accepted in order to not prohibit the ability of people to secure loans (Hilchos Edus 3:4)\r\n",
      "\r\n",
      "\r\n",
      "  דין תורה שאין מקבלין עדות, לא בדיני ממונות ולא בדיני נפשות, אלא מפי העדים:  שנאמר \"על פי שניים עדים\" (דברים יז,ו)--מפיהם, ולא מכתב ידן.  אבל מדברי סופרים שחותכין דיני ממונות בעדות שבשטר, אף על פי שאין העדים קיימין, כדי שלא תנעול דלת בפני לווין.\r\n",
      "\r\n",
      "\n",
      "Your Western Digital hard drive is disappearing as shown in your lsusb output (Port 3):\r\n",
      "\r\n",
      "lsusb -t output:\r\n",
      "\r\n",
      "/:  Bus 01.Port 1: Dev 1, Class=root_hub, Driver=dwc_otg/1p, 480M\r\n",
      "    |__ Port 1: Dev 2, If 0, Class=hub, Driver=hub/3p, 480M\r\n",
      "        |__ Port 1: Dev 3, If 0, Class=vend., Driver=smsc95xx, 480M\r\n",
      "        |__ Port 3: Dev 4, If 0, Class=stor., Driver=usb-storage, 480M\r\n",
      "\r\n",
      "lsusb -t output after a while:\r\n",
      "\r\n",
      "/:  Bus 01.Port 1: Dev 1, Class=root_hub, Driver=dwc_otg/1p, 480M\r\n",
      "    |__ Port 1: Dev 2, If 0, Class=hub, Driver=hub/3p, 480M\r\n",
      "        |__ Port 1: Dev 3, If 0, Class=vend., Driver=smsc95xx, 480M\r\n",
      "\r\n",
      "\r\n",
      "I recommend that you copy all of your data off of this drive to another hard drive before it fails completely. \r\n",
      "\r\n",
      "It is possible that it could be the USB connection on the Pi instead of the drive.  Does the drive behave like this on a different computer system?\r\n",
      "\r\n",
      "Again, I strongly recommend that you backup any irreplaceable data on this drive before it fails completely.  If you have another USB drive I recommend using rsync.  I use the following command to backup one external hard drive to a 2nd device on my Pi where /media/USBHDD1 is the mount point of the 1st drive and /media/USBHDD2 is the mount point of the 2nd drive.  rsync can recover from an interrupted copy in case your drive disappears while performing the copy.  You should be able to just power cycle failed drive and perform the copy command again.  rsync should pick up where it left off.\r\n",
      "\r\n",
      "rsync -av --delete /media/USBHDD1/* /media/USBHDD2/\r\n",
      "\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cached_stopword_list=stopwords.words('english')  ### performance \n",
    "train_data=pd.read_csv('Datasets/train.csv')\n",
    "print(train_data['answer'][3])\n",
    "test_data=pd.read_csv('Datasets/test.csv')\n",
    "print(test_data['answer'][3])\n",
    "\n",
    "# print(cached_stopword_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_tokenization(dataframe):\n",
    "    \n",
    "    answer_list=[]\n",
    "    tokens_list=[]\n",
    "    for row in dataframe['answer']:\n",
    "#         print(row)\n",
    "        tokens=text_to_word_sequence(row,filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\\r') ## adding \\r \n",
    "#         print(tokens)\n",
    "        filtered_sentence=' '.join([word for word in tokens if not word in cached_stopword_list])\n",
    "        filtered_tokens=[word for word in tokens if not word in cached_stopword_list]\n",
    "#         print(filtered_sentence)\n",
    "#         print(filtered_tokens)\n",
    "        answer_list.append(filtered_sentence)\n",
    "        tokens_list.append(filtered_tokens)\n",
    "      \n",
    "    \n",
    "    dataframe['answer_tokens']=tokens_list\n",
    "    dataframe['answer_sentence']=answer_list    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_title</th>\n",
       "      <th>question_body</th>\n",
       "      <th>question_user_name</th>\n",
       "      <th>question_user_page</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_user_name</th>\n",
       "      <th>answer_user_page</th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "      <th>...</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "      <th>answer_tokens</th>\n",
       "      <th>answer_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>What am I losing when using extension tubes in...</td>\n",
       "      <td>After playing around with macro photography on...</td>\n",
       "      <td>ysap</td>\n",
       "      <td>https://photo.stackexchange.com/users/1024</td>\n",
       "      <td>I just got extension tubes, so here's the skin...</td>\n",
       "      <td>rfusca</td>\n",
       "      <td>https://photo.stackexchange.com/users/1917</td>\n",
       "      <td>http://photo.stackexchange.com/questions/9169/...</td>\n",
       "      <td>LIFE_ARTS</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[got, extension, tubes, here's, skinny, losing...</td>\n",
       "      <td>got extension tubes here's skinny losing using...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the distinction between a city and a s...</td>\n",
       "      <td>I am trying to understand what kinds of places...</td>\n",
       "      <td>russellpierce</td>\n",
       "      <td>https://rpg.stackexchange.com/users/8774</td>\n",
       "      <td>It might be helpful to look into the definitio...</td>\n",
       "      <td>Erik Schmidt</td>\n",
       "      <td>https://rpg.stackexchange.com/users/1871</td>\n",
       "      <td>http://rpg.stackexchange.com/questions/47820/w...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>[might, helpful, look, definition, spam, zone,...</td>\n",
       "      <td>might helpful look definition spam zone p 216 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Maximum protusion length for through-hole comp...</td>\n",
       "      <td>I'm working on a PCB that has through-hole com...</td>\n",
       "      <td>Joe Baker</td>\n",
       "      <td>https://electronics.stackexchange.com/users/10157</td>\n",
       "      <td>Do you even need grooves?  We make several pro...</td>\n",
       "      <td>Dwayne Reid</td>\n",
       "      <td>https://electronics.stackexchange.com/users/64754</td>\n",
       "      <td>http://electronics.stackexchange.com/questions...</td>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>[even, need, grooves, make, several, products,...</td>\n",
       "      <td>even need grooves make several products using ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Can an affidavit be used in Beit Din?</td>\n",
       "      <td>An affidavit, from what i understand, is basic...</td>\n",
       "      <td>Scimonster</td>\n",
       "      <td>https://judaism.stackexchange.com/users/5151</td>\n",
       "      <td>Sending an \"affidavit\" it is a dispute between...</td>\n",
       "      <td>Y     e     z</td>\n",
       "      <td>https://judaism.stackexchange.com/users/4794</td>\n",
       "      <td>http://judaism.stackexchange.com/questions/551...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[sending, affidavit, dispute, rashi, rabbeinu,...</td>\n",
       "      <td>sending affidavit dispute rashi rabbeinu tam d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>How do you make a binary image in Photoshop?</td>\n",
       "      <td>I am trying to make a binary image. I want mor...</td>\n",
       "      <td>leigero</td>\n",
       "      <td>https://graphicdesign.stackexchange.com/users/...</td>\n",
       "      <td>Check out Image Trace in Adobe Illustrator. \\r...</td>\n",
       "      <td>q2ra</td>\n",
       "      <td>https://graphicdesign.stackexchange.com/users/...</td>\n",
       "      <td>http://graphicdesign.stackexchange.com/questio...</td>\n",
       "      <td>LIFE_ARTS</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[check, image, trace, adobe, illustrator, like...</td>\n",
       "      <td>check image trace adobe illustrator like using...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6074</th>\n",
       "      <td>9642</td>\n",
       "      <td>Using a ski helmet for winter biking</td>\n",
       "      <td>I am curious if anyone uses a skiing helmet fo...</td>\n",
       "      <td>sixtyfootersdude</td>\n",
       "      <td>https://bicycles.stackexchange.com/users/134</td>\n",
       "      <td>If you're thinking about wearing a ski helmet ...</td>\n",
       "      <td>Matt Leo</td>\n",
       "      <td>https://bicycles.stackexchange.com/users/3340</td>\n",
       "      <td>http://bicycles.stackexchange.com/questions/99...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>[thinking, wearing, ski, helmet, biking, worth...</td>\n",
       "      <td>thinking wearing ski helmet biking worth snell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6075</th>\n",
       "      <td>9643</td>\n",
       "      <td>Adjustment to road bike brakes for high grade ...</td>\n",
       "      <td>I have a road bike with a front brake that wea...</td>\n",
       "      <td>ash</td>\n",
       "      <td>https://bicycles.stackexchange.com/users/14519</td>\n",
       "      <td>\\r\\nYou can replace the pads (as stated elsewh...</td>\n",
       "      <td>Daniel R Hicks</td>\n",
       "      <td>https://bicycles.stackexchange.com/users/1584</td>\n",
       "      <td>http://bicycles.stackexchange.com/questions/25...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>[replace, pads, stated, elsewhere, lot, variat...</td>\n",
       "      <td>replace pads stated elsewhere lot variations p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6076</th>\n",
       "      <td>9645</td>\n",
       "      <td>Suppress 'file truncated' messages when using ...</td>\n",
       "      <td>I'm tailing a log file using tail -f messages....</td>\n",
       "      <td>Maneating Koala</td>\n",
       "      <td>https://unix.stackexchange.com/users/60445</td>\n",
       "      <td>Maybe help if can be fixes origin of this erro...</td>\n",
       "      <td>BG Bruno</td>\n",
       "      <td>https://unix.stackexchange.com/users/68208</td>\n",
       "      <td>http://unix.stackexchange.com/questions/169054...</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>[maybe, help, fixes, origin, error, happened, ...</td>\n",
       "      <td>maybe help fixes origin error happened somethi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6077</th>\n",
       "      <td>9646</td>\n",
       "      <td>When should a supervisor be a co-author?</td>\n",
       "      <td>What are people's views on this?  To be specif...</td>\n",
       "      <td>MrB</td>\n",
       "      <td>https://mathoverflow.net/users/2189</td>\n",
       "      <td>As a non-mathematician, I am somewhat mystifie...</td>\n",
       "      <td>angela</td>\n",
       "      <td>https://mathoverflow.net/users/4267</td>\n",
       "      <td>http://mathoverflow.net/questions/57337</td>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[non, mathematician, somewhat, mystified, prev...</td>\n",
       "      <td>non mathematician somewhat mystified prevailin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6078</th>\n",
       "      <td>9647</td>\n",
       "      <td>Why are there so many different types of screw...</td>\n",
       "      <td>Newbie question.\\r\\n\\r\\nWhy is it that there's...</td>\n",
       "      <td>Doug T.</td>\n",
       "      <td>https://diy.stackexchange.com/users/321</td>\n",
       "      <td>First, I really like Eric's answer for practic...</td>\n",
       "      <td>Scivitri</td>\n",
       "      <td>https://diy.stackexchange.com/users/113</td>\n",
       "      <td>http://diy.stackexchange.com/questions/2701/wh...</td>\n",
       "      <td>LIFE_ARTS</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[first, really, like, eric's, answer, practica...</td>\n",
       "      <td>first really like eric's answer practical reas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6079 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      qa_id                                     question_title  \\\n",
       "0         0  What am I losing when using extension tubes in...   \n",
       "1         1  What is the distinction between a city and a s...   \n",
       "2         2  Maximum protusion length for through-hole comp...   \n",
       "3         3              Can an affidavit be used in Beit Din?   \n",
       "4         5       How do you make a binary image in Photoshop?   \n",
       "...     ...                                                ...   \n",
       "6074   9642               Using a ski helmet for winter biking   \n",
       "6075   9643  Adjustment to road bike brakes for high grade ...   \n",
       "6076   9645  Suppress 'file truncated' messages when using ...   \n",
       "6077   9646           When should a supervisor be a co-author?   \n",
       "6078   9647  Why are there so many different types of screw...   \n",
       "\n",
       "                                          question_body question_user_name  \\\n",
       "0     After playing around with macro photography on...               ysap   \n",
       "1     I am trying to understand what kinds of places...      russellpierce   \n",
       "2     I'm working on a PCB that has through-hole com...          Joe Baker   \n",
       "3     An affidavit, from what i understand, is basic...         Scimonster   \n",
       "4     I am trying to make a binary image. I want mor...            leigero   \n",
       "...                                                 ...                ...   \n",
       "6074  I am curious if anyone uses a skiing helmet fo...   sixtyfootersdude   \n",
       "6075  I have a road bike with a front brake that wea...                ash   \n",
       "6076  I'm tailing a log file using tail -f messages....    Maneating Koala   \n",
       "6077  What are people's views on this?  To be specif...                MrB   \n",
       "6078  Newbie question.\\r\\n\\r\\nWhy is it that there's...            Doug T.   \n",
       "\n",
       "                                     question_user_page  \\\n",
       "0            https://photo.stackexchange.com/users/1024   \n",
       "1              https://rpg.stackexchange.com/users/8774   \n",
       "2     https://electronics.stackexchange.com/users/10157   \n",
       "3          https://judaism.stackexchange.com/users/5151   \n",
       "4     https://graphicdesign.stackexchange.com/users/...   \n",
       "...                                                 ...   \n",
       "6074       https://bicycles.stackexchange.com/users/134   \n",
       "6075     https://bicycles.stackexchange.com/users/14519   \n",
       "6076         https://unix.stackexchange.com/users/60445   \n",
       "6077                https://mathoverflow.net/users/2189   \n",
       "6078            https://diy.stackexchange.com/users/321   \n",
       "\n",
       "                                                 answer answer_user_name  \\\n",
       "0     I just got extension tubes, so here's the skin...           rfusca   \n",
       "1     It might be helpful to look into the definitio...     Erik Schmidt   \n",
       "2     Do you even need grooves?  We make several pro...      Dwayne Reid   \n",
       "3     Sending an \"affidavit\" it is a dispute between...    Y     e     z   \n",
       "4     Check out Image Trace in Adobe Illustrator. \\r...             q2ra   \n",
       "...                                                 ...              ...   \n",
       "6074  If you're thinking about wearing a ski helmet ...         Matt Leo   \n",
       "6075  \\r\\nYou can replace the pads (as stated elsewh...   Daniel R Hicks   \n",
       "6076  Maybe help if can be fixes origin of this erro...         BG Bruno   \n",
       "6077  As a non-mathematician, I am somewhat mystifie...           angela   \n",
       "6078  First, I really like Eric's answer for practic...         Scivitri   \n",
       "\n",
       "                                       answer_user_page  \\\n",
       "0            https://photo.stackexchange.com/users/1917   \n",
       "1              https://rpg.stackexchange.com/users/1871   \n",
       "2     https://electronics.stackexchange.com/users/64754   \n",
       "3          https://judaism.stackexchange.com/users/4794   \n",
       "4     https://graphicdesign.stackexchange.com/users/...   \n",
       "...                                                 ...   \n",
       "6074      https://bicycles.stackexchange.com/users/3340   \n",
       "6075      https://bicycles.stackexchange.com/users/1584   \n",
       "6076         https://unix.stackexchange.com/users/68208   \n",
       "6077                https://mathoverflow.net/users/4267   \n",
       "6078            https://diy.stackexchange.com/users/113   \n",
       "\n",
       "                                                    url    category  ...  \\\n",
       "0     http://photo.stackexchange.com/questions/9169/...   LIFE_ARTS  ...   \n",
       "1     http://rpg.stackexchange.com/questions/47820/w...     CULTURE  ...   \n",
       "2     http://electronics.stackexchange.com/questions...     SCIENCE  ...   \n",
       "3     http://judaism.stackexchange.com/questions/551...     CULTURE  ...   \n",
       "4     http://graphicdesign.stackexchange.com/questio...   LIFE_ARTS  ...   \n",
       "...                                                 ...         ...  ...   \n",
       "6074  http://bicycles.stackexchange.com/questions/99...     CULTURE  ...   \n",
       "6075  http://bicycles.stackexchange.com/questions/25...     CULTURE  ...   \n",
       "6076  http://unix.stackexchange.com/questions/169054...  TECHNOLOGY  ...   \n",
       "6077            http://mathoverflow.net/questions/57337     SCIENCE  ...   \n",
       "6078  http://diy.stackexchange.com/questions/2701/wh...   LIFE_ARTS  ...   \n",
       "\n",
       "     answer_level_of_information  answer_plausible  answer_relevance  \\\n",
       "0                       0.666667          1.000000          1.000000   \n",
       "1                       0.555556          0.888889          0.888889   \n",
       "2                       0.555556          1.000000          1.000000   \n",
       "3                       0.333333          0.833333          1.000000   \n",
       "4                       0.666667          1.000000          1.000000   \n",
       "...                          ...               ...               ...   \n",
       "6074                    0.555556          1.000000          1.000000   \n",
       "6075                    0.555556          1.000000          1.000000   \n",
       "6076                    0.555556          0.888889          0.888889   \n",
       "6077                    0.555556          1.000000          1.000000   \n",
       "6078                    0.555556          1.000000          0.888889   \n",
       "\n",
       "      answer_satisfaction  answer_type_instructions  answer_type_procedure  \\\n",
       "0                0.800000                  1.000000               0.000000   \n",
       "1                0.666667                  0.000000               0.000000   \n",
       "2                0.666667                  0.000000               0.333333   \n",
       "3                0.800000                  0.000000               0.000000   \n",
       "4                0.800000                  1.000000               0.000000   \n",
       "...                   ...                       ...                    ...   \n",
       "6074             0.866667                  0.000000               0.000000   \n",
       "6075             0.733333                  0.666667               0.333333   \n",
       "6076             0.800000                  1.000000               0.000000   \n",
       "6077             0.533333                  0.000000               0.333333   \n",
       "6078             0.733333                  0.000000               0.000000   \n",
       "\n",
       "      answer_type_reason_explanation  answer_well_written  \\\n",
       "0                           0.000000             1.000000   \n",
       "1                           0.666667             0.888889   \n",
       "2                           1.000000             0.888889   \n",
       "3                           1.000000             1.000000   \n",
       "4                           1.000000             1.000000   \n",
       "...                              ...                  ...   \n",
       "6074                        0.000000             0.888889   \n",
       "6075                        0.000000             0.888889   \n",
       "6076                        0.333333             0.555556   \n",
       "6077                        0.666667             1.000000   \n",
       "6078                        1.000000             1.000000   \n",
       "\n",
       "                                          answer_tokens  \\\n",
       "0     [got, extension, tubes, here's, skinny, losing...   \n",
       "1     [might, helpful, look, definition, spam, zone,...   \n",
       "2     [even, need, grooves, make, several, products,...   \n",
       "3     [sending, affidavit, dispute, rashi, rabbeinu,...   \n",
       "4     [check, image, trace, adobe, illustrator, like...   \n",
       "...                                                 ...   \n",
       "6074  [thinking, wearing, ski, helmet, biking, worth...   \n",
       "6075  [replace, pads, stated, elsewhere, lot, variat...   \n",
       "6076  [maybe, help, fixes, origin, error, happened, ...   \n",
       "6077  [non, mathematician, somewhat, mystified, prev...   \n",
       "6078  [first, really, like, eric's, answer, practica...   \n",
       "\n",
       "                                        answer_sentence  \n",
       "0     got extension tubes here's skinny losing using...  \n",
       "1     might helpful look definition spam zone p 216 ...  \n",
       "2     even need grooves make several products using ...  \n",
       "3     sending affidavit dispute rashi rabbeinu tam d...  \n",
       "4     check image trace adobe illustrator like using...  \n",
       "...                                                 ...  \n",
       "6074  thinking wearing ski helmet biking worth snell...  \n",
       "6075  replace pads stated elsewhere lot variations p...  \n",
       "6076  maybe help fixes origin error happened somethi...  \n",
       "6077  non mathematician somewhat mystified prevailin...  \n",
       "6078  first really like eric's answer practical reas...  \n",
       "\n",
       "[6079 rows x 43 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_tokenization(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle best approaches\n",
    "###  https://www.kaggle.com/rahulvv/bidirectional-lstm-glove200d '''\n",
    "''' import string\n",
    "import re\n",
    "\n",
    "### remove urls\n",
    "def remove_urls(text):\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url.sub(r'',text)\n",
    "  \n",
    "#remove html tags\n",
    "def remove_html(text):\n",
    "    html=re.compile(r'<.*?>')\n",
    "    return html.sub(r'',text)\n",
    "\n",
    "### splitting the text\n",
    "def split_text(text):\n",
    "    text = text.split()\n",
    "    return text\n",
    "\n",
    "### making lower case words\n",
    "def lower(text):\n",
    "    text = [word.lower() for word in text]\n",
    "    return str(text)\n",
    "\n",
    "### remove punct\n",
    "def remove_punct(text):\n",
    "    text = ''.join([char for char in text if char not in string.punctuation])\n",
    "    text = re.sub('[0-9]+', '', str(text))\n",
    "    return text\n",
    "\n",
    "## remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    pattern = re.compile(r'\\b('+r'|'.join(stopwords.words('english')) + r')\\b\\s*')\n",
    "    text = pattern.sub(' ', text)\n",
    "    return text\n",
    "\n",
    "## lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_words(text):\n",
    "    text = lemmatizer.lemmatize(text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def final(text):\n",
    "    t0 = remove_urls(text)\n",
    "    t1 = remove_html(t0)\n",
    "    t2 = split_text(t1)\n",
    "    t3 = lower(t2)\n",
    "    t4 = remove_punct(t3)\n",
    "    t5 = remove_stopwords(t4)\n",
    "    t6 = lemmatize_words(t5)\n",
    "    return t6\n",
    "\n",
    "train_sentences = train_data.question_body.values\n",
    "\n",
    "#### train_labels = train_df.target.values\n",
    "test_sentences = test_data.question_body.values\n",
    "training_sentences = []\n",
    "for i in range(len(train_sentences)):\n",
    "    data = final(train_sentences[i])\n",
    "    training_sentences.append(data)\n",
    "\n",
    "testing_sentences = []\n",
    "for i in range(len(test_sentences)):\n",
    "    data = final(test_sentences[i])\n",
    "    testing_sentences.append(data)\n",
    "print(training_sentences[1])  '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_tokenization(text):\n",
    "    sent_list=[]\n",
    "    tokens_list=[]\n",
    "    for row in text:\n",
    "        tokens=text_to_word_sequence(row,filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\\r') ## adding \\r \n",
    "        filtered_sentence=' '.join([word for word in tokens if not word in cached_stopword_list])\n",
    "        filtered_tokens=[word for word in tokens if not word in cached_stopword_list]\n",
    "        sent_list.append(filtered_sentence)\n",
    "        tokens_list.append(filtered_tokens)\n",
    "    return sent_list,tokens_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_text=train_data.question_body\n",
    "# question_sent,question_tokens=keras_tokenization(question_text)\n",
    "train_data['question_sent'],train_data['question_tokens']=keras_tokenization(question_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_title</th>\n",
       "      <th>question_body</th>\n",
       "      <th>question_user_name</th>\n",
       "      <th>question_user_page</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_user_name</th>\n",
       "      <th>answer_user_page</th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "      <th>...</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "      <th>answer_tokens</th>\n",
       "      <th>answer_sentence</th>\n",
       "      <th>question_sent</th>\n",
       "      <th>question_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>What am I losing when using extension tubes in...</td>\n",
       "      <td>After playing around with macro photography on...</td>\n",
       "      <td>ysap</td>\n",
       "      <td>https://photo.stackexchange.com/users/1024</td>\n",
       "      <td>I just got extension tubes, so here's the skin...</td>\n",
       "      <td>rfusca</td>\n",
       "      <td>https://photo.stackexchange.com/users/1917</td>\n",
       "      <td>http://photo.stackexchange.com/questions/9169/...</td>\n",
       "      <td>LIFE_ARTS</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[got, extension, tubes, here's, skinny, losing...</td>\n",
       "      <td>got extension tubes here's skinny losing using...</td>\n",
       "      <td>playing around macro photography cheap read re...</td>\n",
       "      <td>[playing, around, macro, photography, cheap, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the distinction between a city and a s...</td>\n",
       "      <td>I am trying to understand what kinds of places...</td>\n",
       "      <td>russellpierce</td>\n",
       "      <td>https://rpg.stackexchange.com/users/8774</td>\n",
       "      <td>It might be helpful to look into the definitio...</td>\n",
       "      <td>Erik Schmidt</td>\n",
       "      <td>https://rpg.stackexchange.com/users/1871</td>\n",
       "      <td>http://rpg.stackexchange.com/questions/47820/w...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>[might, helpful, look, definition, spam, zone,...</td>\n",
       "      <td>might helpful look definition spam zone p 216 ...</td>\n",
       "      <td>trying understand kinds places spam values p 2...</td>\n",
       "      <td>[trying, understand, kinds, places, spam, valu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Maximum protusion length for through-hole comp...</td>\n",
       "      <td>I'm working on a PCB that has through-hole com...</td>\n",
       "      <td>Joe Baker</td>\n",
       "      <td>https://electronics.stackexchange.com/users/10157</td>\n",
       "      <td>Do you even need grooves?  We make several pro...</td>\n",
       "      <td>Dwayne Reid</td>\n",
       "      <td>https://electronics.stackexchange.com/users/64754</td>\n",
       "      <td>http://electronics.stackexchange.com/questions...</td>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>[even, need, grooves, make, several, products,...</td>\n",
       "      <td>even need grooves make several products using ...</td>\n",
       "      <td>i'm working pcb hole components sides board to...</td>\n",
       "      <td>[i'm, working, pcb, hole, components, sides, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Can an affidavit be used in Beit Din?</td>\n",
       "      <td>An affidavit, from what i understand, is basic...</td>\n",
       "      <td>Scimonster</td>\n",
       "      <td>https://judaism.stackexchange.com/users/5151</td>\n",
       "      <td>Sending an \"affidavit\" it is a dispute between...</td>\n",
       "      <td>Y     e     z</td>\n",
       "      <td>https://judaism.stackexchange.com/users/4794</td>\n",
       "      <td>http://judaism.stackexchange.com/questions/551...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[sending, affidavit, dispute, rashi, rabbeinu,...</td>\n",
       "      <td>sending affidavit dispute rashi rabbeinu tam d...</td>\n",
       "      <td>affidavit understand basically signed document...</td>\n",
       "      <td>[affidavit, understand, basically, signed, doc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>How do you make a binary image in Photoshop?</td>\n",
       "      <td>I am trying to make a binary image. I want mor...</td>\n",
       "      <td>leigero</td>\n",
       "      <td>https://graphicdesign.stackexchange.com/users/...</td>\n",
       "      <td>Check out Image Trace in Adobe Illustrator. \\r...</td>\n",
       "      <td>q2ra</td>\n",
       "      <td>https://graphicdesign.stackexchange.com/users/...</td>\n",
       "      <td>http://graphicdesign.stackexchange.com/questio...</td>\n",
       "      <td>LIFE_ARTS</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[check, image, trace, adobe, illustrator, like...</td>\n",
       "      <td>check image trace adobe illustrator like using...</td>\n",
       "      <td>trying make binary image want look image black...</td>\n",
       "      <td>[trying, make, binary, image, want, look, imag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6074</th>\n",
       "      <td>9642</td>\n",
       "      <td>Using a ski helmet for winter biking</td>\n",
       "      <td>I am curious if anyone uses a skiing helmet fo...</td>\n",
       "      <td>sixtyfootersdude</td>\n",
       "      <td>https://bicycles.stackexchange.com/users/134</td>\n",
       "      <td>If you're thinking about wearing a ski helmet ...</td>\n",
       "      <td>Matt Leo</td>\n",
       "      <td>https://bicycles.stackexchange.com/users/3340</td>\n",
       "      <td>http://bicycles.stackexchange.com/questions/99...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>[thinking, wearing, ski, helmet, biking, worth...</td>\n",
       "      <td>thinking wearing ski helmet biking worth snell...</td>\n",
       "      <td>curious anyone uses skiing helmet winter bikin...</td>\n",
       "      <td>[curious, anyone, uses, skiing, helmet, winter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6075</th>\n",
       "      <td>9643</td>\n",
       "      <td>Adjustment to road bike brakes for high grade ...</td>\n",
       "      <td>I have a road bike with a front brake that wea...</td>\n",
       "      <td>ash</td>\n",
       "      <td>https://bicycles.stackexchange.com/users/14519</td>\n",
       "      <td>\\r\\nYou can replace the pads (as stated elsewh...</td>\n",
       "      <td>Daniel R Hicks</td>\n",
       "      <td>https://bicycles.stackexchange.com/users/1584</td>\n",
       "      <td>http://bicycles.stackexchange.com/questions/25...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>[replace, pads, stated, elsewhere, lot, variat...</td>\n",
       "      <td>replace pads stated elsewhere lot variations p...</td>\n",
       "      <td>road bike front brake wears lot brake pad ride...</td>\n",
       "      <td>[road, bike, front, brake, wears, lot, brake, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6076</th>\n",
       "      <td>9645</td>\n",
       "      <td>Suppress 'file truncated' messages when using ...</td>\n",
       "      <td>I'm tailing a log file using tail -f messages....</td>\n",
       "      <td>Maneating Koala</td>\n",
       "      <td>https://unix.stackexchange.com/users/60445</td>\n",
       "      <td>Maybe help if can be fixes origin of this erro...</td>\n",
       "      <td>BG Bruno</td>\n",
       "      <td>https://unix.stackexchange.com/users/68208</td>\n",
       "      <td>http://unix.stackexchange.com/questions/169054...</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>[maybe, help, fixes, origin, error, happened, ...</td>\n",
       "      <td>maybe help fixes origin error happened somethi...</td>\n",
       "      <td>i'm tailing log file using tail f messages log...</td>\n",
       "      <td>[i'm, tailing, log, file, using, tail, f, mess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6077</th>\n",
       "      <td>9646</td>\n",
       "      <td>When should a supervisor be a co-author?</td>\n",
       "      <td>What are people's views on this?  To be specif...</td>\n",
       "      <td>MrB</td>\n",
       "      <td>https://mathoverflow.net/users/2189</td>\n",
       "      <td>As a non-mathematician, I am somewhat mystifie...</td>\n",
       "      <td>angela</td>\n",
       "      <td>https://mathoverflow.net/users/4267</td>\n",
       "      <td>http://mathoverflow.net/questions/57337</td>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[non, mathematician, somewhat, mystified, prev...</td>\n",
       "      <td>non mathematician somewhat mystified prevailin...</td>\n",
       "      <td>people's views specific suppose phd student pr...</td>\n",
       "      <td>[people's, views, specific, suppose, phd, stud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6078</th>\n",
       "      <td>9647</td>\n",
       "      <td>Why are there so many different types of screw...</td>\n",
       "      <td>Newbie question.\\r\\n\\r\\nWhy is it that there's...</td>\n",
       "      <td>Doug T.</td>\n",
       "      <td>https://diy.stackexchange.com/users/321</td>\n",
       "      <td>First, I really like Eric's answer for practic...</td>\n",
       "      <td>Scivitri</td>\n",
       "      <td>https://diy.stackexchange.com/users/113</td>\n",
       "      <td>http://diy.stackexchange.com/questions/2701/wh...</td>\n",
       "      <td>LIFE_ARTS</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[first, really, like, eric's, answer, practica...</td>\n",
       "      <td>first really like eric's answer practical reas...</td>\n",
       "      <td>newbie question there's bazillion different ty...</td>\n",
       "      <td>[newbie, question, there's, bazillion, differe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6079 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      qa_id                                     question_title  \\\n",
       "0         0  What am I losing when using extension tubes in...   \n",
       "1         1  What is the distinction between a city and a s...   \n",
       "2         2  Maximum protusion length for through-hole comp...   \n",
       "3         3              Can an affidavit be used in Beit Din?   \n",
       "4         5       How do you make a binary image in Photoshop?   \n",
       "...     ...                                                ...   \n",
       "6074   9642               Using a ski helmet for winter biking   \n",
       "6075   9643  Adjustment to road bike brakes for high grade ...   \n",
       "6076   9645  Suppress 'file truncated' messages when using ...   \n",
       "6077   9646           When should a supervisor be a co-author?   \n",
       "6078   9647  Why are there so many different types of screw...   \n",
       "\n",
       "                                          question_body question_user_name  \\\n",
       "0     After playing around with macro photography on...               ysap   \n",
       "1     I am trying to understand what kinds of places...      russellpierce   \n",
       "2     I'm working on a PCB that has through-hole com...          Joe Baker   \n",
       "3     An affidavit, from what i understand, is basic...         Scimonster   \n",
       "4     I am trying to make a binary image. I want mor...            leigero   \n",
       "...                                                 ...                ...   \n",
       "6074  I am curious if anyone uses a skiing helmet fo...   sixtyfootersdude   \n",
       "6075  I have a road bike with a front brake that wea...                ash   \n",
       "6076  I'm tailing a log file using tail -f messages....    Maneating Koala   \n",
       "6077  What are people's views on this?  To be specif...                MrB   \n",
       "6078  Newbie question.\\r\\n\\r\\nWhy is it that there's...            Doug T.   \n",
       "\n",
       "                                     question_user_page  \\\n",
       "0            https://photo.stackexchange.com/users/1024   \n",
       "1              https://rpg.stackexchange.com/users/8774   \n",
       "2     https://electronics.stackexchange.com/users/10157   \n",
       "3          https://judaism.stackexchange.com/users/5151   \n",
       "4     https://graphicdesign.stackexchange.com/users/...   \n",
       "...                                                 ...   \n",
       "6074       https://bicycles.stackexchange.com/users/134   \n",
       "6075     https://bicycles.stackexchange.com/users/14519   \n",
       "6076         https://unix.stackexchange.com/users/60445   \n",
       "6077                https://mathoverflow.net/users/2189   \n",
       "6078            https://diy.stackexchange.com/users/321   \n",
       "\n",
       "                                                 answer answer_user_name  \\\n",
       "0     I just got extension tubes, so here's the skin...           rfusca   \n",
       "1     It might be helpful to look into the definitio...     Erik Schmidt   \n",
       "2     Do you even need grooves?  We make several pro...      Dwayne Reid   \n",
       "3     Sending an \"affidavit\" it is a dispute between...    Y     e     z   \n",
       "4     Check out Image Trace in Adobe Illustrator. \\r...             q2ra   \n",
       "...                                                 ...              ...   \n",
       "6074  If you're thinking about wearing a ski helmet ...         Matt Leo   \n",
       "6075  \\r\\nYou can replace the pads (as stated elsewh...   Daniel R Hicks   \n",
       "6076  Maybe help if can be fixes origin of this erro...         BG Bruno   \n",
       "6077  As a non-mathematician, I am somewhat mystifie...           angela   \n",
       "6078  First, I really like Eric's answer for practic...         Scivitri   \n",
       "\n",
       "                                       answer_user_page  \\\n",
       "0            https://photo.stackexchange.com/users/1917   \n",
       "1              https://rpg.stackexchange.com/users/1871   \n",
       "2     https://electronics.stackexchange.com/users/64754   \n",
       "3          https://judaism.stackexchange.com/users/4794   \n",
       "4     https://graphicdesign.stackexchange.com/users/...   \n",
       "...                                                 ...   \n",
       "6074      https://bicycles.stackexchange.com/users/3340   \n",
       "6075      https://bicycles.stackexchange.com/users/1584   \n",
       "6076         https://unix.stackexchange.com/users/68208   \n",
       "6077                https://mathoverflow.net/users/4267   \n",
       "6078            https://diy.stackexchange.com/users/113   \n",
       "\n",
       "                                                    url    category  ...  \\\n",
       "0     http://photo.stackexchange.com/questions/9169/...   LIFE_ARTS  ...   \n",
       "1     http://rpg.stackexchange.com/questions/47820/w...     CULTURE  ...   \n",
       "2     http://electronics.stackexchange.com/questions...     SCIENCE  ...   \n",
       "3     http://judaism.stackexchange.com/questions/551...     CULTURE  ...   \n",
       "4     http://graphicdesign.stackexchange.com/questio...   LIFE_ARTS  ...   \n",
       "...                                                 ...         ...  ...   \n",
       "6074  http://bicycles.stackexchange.com/questions/99...     CULTURE  ...   \n",
       "6075  http://bicycles.stackexchange.com/questions/25...     CULTURE  ...   \n",
       "6076  http://unix.stackexchange.com/questions/169054...  TECHNOLOGY  ...   \n",
       "6077            http://mathoverflow.net/questions/57337     SCIENCE  ...   \n",
       "6078  http://diy.stackexchange.com/questions/2701/wh...   LIFE_ARTS  ...   \n",
       "\n",
       "     answer_relevance  answer_satisfaction  answer_type_instructions  \\\n",
       "0            1.000000             0.800000                  1.000000   \n",
       "1            0.888889             0.666667                  0.000000   \n",
       "2            1.000000             0.666667                  0.000000   \n",
       "3            1.000000             0.800000                  0.000000   \n",
       "4            1.000000             0.800000                  1.000000   \n",
       "...               ...                  ...                       ...   \n",
       "6074         1.000000             0.866667                  0.000000   \n",
       "6075         1.000000             0.733333                  0.666667   \n",
       "6076         0.888889             0.800000                  1.000000   \n",
       "6077         1.000000             0.533333                  0.000000   \n",
       "6078         0.888889             0.733333                  0.000000   \n",
       "\n",
       "      answer_type_procedure  answer_type_reason_explanation  \\\n",
       "0                  0.000000                        0.000000   \n",
       "1                  0.000000                        0.666667   \n",
       "2                  0.333333                        1.000000   \n",
       "3                  0.000000                        1.000000   \n",
       "4                  0.000000                        1.000000   \n",
       "...                     ...                             ...   \n",
       "6074               0.000000                        0.000000   \n",
       "6075               0.333333                        0.000000   \n",
       "6076               0.000000                        0.333333   \n",
       "6077               0.333333                        0.666667   \n",
       "6078               0.000000                        1.000000   \n",
       "\n",
       "      answer_well_written                                      answer_tokens  \\\n",
       "0                1.000000  [got, extension, tubes, here's, skinny, losing...   \n",
       "1                0.888889  [might, helpful, look, definition, spam, zone,...   \n",
       "2                0.888889  [even, need, grooves, make, several, products,...   \n",
       "3                1.000000  [sending, affidavit, dispute, rashi, rabbeinu,...   \n",
       "4                1.000000  [check, image, trace, adobe, illustrator, like...   \n",
       "...                   ...                                                ...   \n",
       "6074             0.888889  [thinking, wearing, ski, helmet, biking, worth...   \n",
       "6075             0.888889  [replace, pads, stated, elsewhere, lot, variat...   \n",
       "6076             0.555556  [maybe, help, fixes, origin, error, happened, ...   \n",
       "6077             1.000000  [non, mathematician, somewhat, mystified, prev...   \n",
       "6078             1.000000  [first, really, like, eric's, answer, practica...   \n",
       "\n",
       "                                        answer_sentence  \\\n",
       "0     got extension tubes here's skinny losing using...   \n",
       "1     might helpful look definition spam zone p 216 ...   \n",
       "2     even need grooves make several products using ...   \n",
       "3     sending affidavit dispute rashi rabbeinu tam d...   \n",
       "4     check image trace adobe illustrator like using...   \n",
       "...                                                 ...   \n",
       "6074  thinking wearing ski helmet biking worth snell...   \n",
       "6075  replace pads stated elsewhere lot variations p...   \n",
       "6076  maybe help fixes origin error happened somethi...   \n",
       "6077  non mathematician somewhat mystified prevailin...   \n",
       "6078  first really like eric's answer practical reas...   \n",
       "\n",
       "                                          question_sent  \\\n",
       "0     playing around macro photography cheap read re...   \n",
       "1     trying understand kinds places spam values p 2...   \n",
       "2     i'm working pcb hole components sides board to...   \n",
       "3     affidavit understand basically signed document...   \n",
       "4     trying make binary image want look image black...   \n",
       "...                                                 ...   \n",
       "6074  curious anyone uses skiing helmet winter bikin...   \n",
       "6075  road bike front brake wears lot brake pad ride...   \n",
       "6076  i'm tailing log file using tail f messages log...   \n",
       "6077  people's views specific suppose phd student pr...   \n",
       "6078  newbie question there's bazillion different ty...   \n",
       "\n",
       "                                        question_tokens  \n",
       "0     [playing, around, macro, photography, cheap, r...  \n",
       "1     [trying, understand, kinds, places, spam, valu...  \n",
       "2     [i'm, working, pcb, hole, components, sides, b...  \n",
       "3     [affidavit, understand, basically, signed, doc...  \n",
       "4     [trying, make, binary, image, want, look, imag...  \n",
       "...                                                 ...  \n",
       "6074  [curious, anyone, uses, skiing, helmet, winter...  \n",
       "6075  [road, bike, front, brake, wears, lot, brake, ...  \n",
       "6076  [i'm, tailing, log, file, using, tail, f, mess...  \n",
       "6077  [people's, views, specific, suppose, phd, stud...  \n",
       "6078  [newbie, question, there's, bazillion, differe...  \n",
       "\n",
       "[6079 rows x 45 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(question_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(question_sent[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## breaking into modules\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['after', 'playing', 'around', 'with', 'macro', 'photography', 'on', 'the', 'cheap', 'read', 'reversed', 'lens', 'rev', 'lens', 'mounted', 'on', 'a', 'straight', 'lens', 'passive', 'extension', 'tubes', 'i', 'would', 'like', 'to', 'get', 'further', 'with', 'this', 'the', 'problems', 'with', 'the', 'techniques', 'i', 'used', 'is', 'that', 'focus', 'is', 'manual', 'and', 'aperture', 'control', 'is', 'problematic', 'at', 'best', 'this', 'limited', 'my', 'setup', 'to', 'still', 'subjects', 'read', 'dead', 'insects', 'now', 'as', 'spring', 'is', 'approaching', 'i', 'want', 'to', 'be', 'able', 'to', 'shoot', 'live', 'insects', 'i', 'believe', 'that', 'for', 'this', 'autofocus', 'and', 'settable', 'aperture', 'will', 'be', 'of', 'great', 'help', 'so', 'one', 'obvious', 'but', 'expensive', 'option', 'is', 'a', 'macro', 'lens', 'say', 'ef', '100mm', 'macro', 'however', 'i', 'am', 'not', 'really', 'interested', 'in', 'yet', 'another', 'prime', 'lens', 'an', 'alternative', 'is', 'the', 'electrical', 'extension', 'tubes', 'except', 'for', 'maximum', 'focusing', 'distance', 'what', 'am', 'i', 'losing', 'when', 'using', 'tubes', 'coupled', 'with', 'a', 'fine', 'lens', 'say', 'ef70', '200', '2', '8', 'instead', 'of', 'a', 'macro', 'lens']\n",
      "playing around macro photography cheap read reversed lens rev lens mounted straight lens passive extension tubes would like get problems techniques used focus manual aperture control problematic best limited setup still subjects read dead insects spring approaching want able shoot live insects believe autofocus settable aperture great help one obvious expensive option macro lens say ef 100mm macro however really interested yet another prime lens alternative electrical extension tubes except maximum focusing distance losing using tubes coupled fine lens say ef70 200 2 8 instead macro lens\n"
     ]
    }
   ],
   "source": [
    "def tokenization(text):\n",
    "    return(text_to_word_sequence(text,filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\\r'))\n",
    "print(tokenization(question_text[0]))\n",
    "tokens=tokenization(question_text[0])\n",
    "\n",
    "def stopword_removal(text):\n",
    "    return(' '.join([word for word in text if not word in cached_stopword_list]))\n",
    "print(stopword_removal(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "question_text_sent_list=[]\n",
    "answer_text_sent_list=[]\n",
    "\n",
    "for i in train_data['question_body']:\n",
    "    quest_tokens=tokenization(i)\n",
    "    quest_sent=stopword_removal(quest_tokens)\n",
    "#     print(quest_sent)\n",
    "    \n",
    "    question_text_sent_list.append(quest_sent)\n",
    "# print((question_text_sent_list[:5])) \n",
    "\n",
    "\n",
    "for i in train_data['answer']:\n",
    "    ans_tokens=tokenization(i)\n",
    "    ans_sent=stopword_removal(quest_tokens)\n",
    "    answer_text_sent_list.append(quest_sent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### benchmarking each step using time function and creating logs and saving logs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "### Glove Model running\n",
    "word2vec = {}\n",
    "with open('/Kaggle-Google-QUEST-QA-Labeling/Vectors/glove.6B.200d.txt',encoding='utf-8') as vec_file:\n",
    "    for line in vec_file:\n",
    "        values=line.split()\n",
    "#         print(values)\n",
    "        words=values[0]\n",
    "        vec = np.asarray(values[1:], dtype='float32') \n",
    "        word2vec[words]=vec\n",
    "    print('Found %s word vectors.' % len(word2vec))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(word2vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 200\n",
    "embedding_dim = 200\n",
    "max_length = 32\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = 'OOV'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique tokens generated:  30528\n",
      "Padded Sequences: [[  1   1   1 ...   1  87   1]\n",
      " [ 80 160   1 ...   1   1  11]\n",
      " [  9 131   1 ...   1  67   1]\n",
      " ...\n",
      " [  9   1 187 ...   1   1   1]\n",
      " [  1   1   1 ...   1   1  53]\n",
      " [  1  29   1 ...   0   0   0]]\n",
      "Shape of padded train tensor:  (6079, 32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer=Tokenizer(num_words=num_words, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(question_text_sent_list)\n",
    "\n",
    "question_text_seq=tokenizer.texts_to_sequences(question_text_sent_list)\n",
    "# print('Question_text_sequence:',question_text_seq)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Total unique tokens generated: ',len(word_index))\n",
    "\n",
    "padded_train = pad_sequences(sequences=question_text_seq, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "print('Padded Sequences:',padded_train)\n",
    "print('Shape of padded train tensor: ', padded_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "(20000, 200)\n"
     ]
    }
   ],
   "source": [
    "num_words = min(20000, len(word_index)+1)\n",
    "print(num_words)\n",
    "\n",
    "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
    "print(np.shape(embedding_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embeddings = []\n",
    "for word, i in word_index.items():\n",
    "    \n",
    "    if i<num_words:\n",
    "        embeddings = word2vec.get(word)\n",
    "        if embeddings is not None:\n",
    "            embedding_matrix[i] = embeddings\n",
    "            \n",
    "        \n",
    "# print(embedding_matrix[1])            \n",
    "# print(np.shape(embedding_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
